{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\n\nimport string\nfrom string import digits\n\nimport numpy as np\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.utils import to_categorical\n\n\nfrom nltk.tokenize import word_tokenize\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\n\nimport matplotlib.pyplot as plt\n\nlemmatizer = WordNetLemmatizer()\nstop_words = set(stopwords.words('english'))","metadata":{"execution":{"iopub.status.busy":"2023-05-08T23:37:13.866818Z","iopub.execute_input":"2023-05-08T23:37:13.867218Z","iopub.status.idle":"2023-05-08T23:37:26.531126Z","shell.execute_reply.started":"2023-05-08T23:37:13.867181Z","shell.execute_reply":"2023-05-08T23:37:26.529984Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T23:37:26.536837Z","iopub.execute_input":"2023-05-08T23:37:26.539405Z","iopub.status.idle":"2023-05-08T23:37:28.348089Z","shell.execute_reply.started":"2023-05-08T23:37:26.539363Z","shell.execute_reply":"2023-05-08T23:37:28.347091Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                              review sentiment\n0  One of the other reviewers has mentioned that ...  positive\n1  A wonderful little production. <br /><br />The...  positive\n2  I thought this was a wonderful way to spend ti...  positive\n3  Basically there's a family where a little boy ...  negative\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn import preprocessing\nle =  preprocessing.LabelEncoder()\ndf[\"sentiment\"] = le.fit_transform(df['sentiment'])","metadata":{"execution":{"iopub.status.busy":"2023-05-08T23:37:28.352506Z","iopub.execute_input":"2023-05-08T23:37:28.354701Z","iopub.status.idle":"2023-05-08T23:37:28.382805Z","shell.execute_reply.started":"2023-05-08T23:37:28.354659Z","shell.execute_reply":"2023-05-08T23:37:28.381811Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df.head","metadata":{"execution":{"iopub.status.busy":"2023-05-08T23:37:28.388433Z","iopub.execute_input":"2023-05-08T23:37:28.390788Z","iopub.status.idle":"2023-05-08T23:37:28.405977Z","shell.execute_reply.started":"2023-05-08T23:37:28.390741Z","shell.execute_reply":"2023-05-08T23:37:28.404713Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"<bound method NDFrame.head of                                                   review  sentiment\n0      One of the other reviewers has mentioned that ...          1\n1      A wonderful little production. <br /><br />The...          1\n2      I thought this was a wonderful way to spend ti...          1\n3      Basically there's a family where a little boy ...          0\n4      Petter Mattei's \"Love in the Time of Money\" is...          1\n...                                                  ...        ...\n49995  I thought this movie did a down right good job...          1\n49996  Bad plot, bad dialogue, bad acting, idiotic di...          0\n49997  I am a Catholic taught in parochial elementary...          0\n49998  I'm going to have to disagree with the previou...          0\n49999  No one expects the Star Trek movies to be high...          0\n\n[50000 rows x 2 columns]>"},"metadata":{}}]},{"cell_type":"code","source":"df.isnull().sum()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T23:37:28.410629Z","iopub.execute_input":"2023-05-08T23:37:28.412879Z","iopub.status.idle":"2023-05-08T23:37:28.435307Z","shell.execute_reply.started":"2023-05-08T23:37:28.412835Z","shell.execute_reply":"2023-05-08T23:37:28.433314Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"review       0\nsentiment    0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"X = df[\"review\"]\ny = df[\"sentiment\"]","metadata":{"execution":{"iopub.status.busy":"2023-05-08T23:37:28.440244Z","iopub.execute_input":"2023-05-08T23:37:28.442657Z","iopub.status.idle":"2023-05-08T23:37:28.448988Z","shell.execute_reply.started":"2023-05-08T23:37:28.442611Z","shell.execute_reply":"2023-05-08T23:37:28.447993Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def stringprocess(text):\n    text = re.sub(r\"what's\", \"what is \", text)\n    text = re.sub(r\"\\'s\", \" is\", text)\n    text = re.sub(r\"\\'ve\", \" have \", text)\n    text = re.sub(r\"can't\", \"cannot \", text)\n    text = re.sub(r\"n't\", \" not \", text)\n    text = re.sub(r\"i'm\", \"i am \", text)\n    text = re.sub(r\"\\'re\", \" are \", text)\n    text = re.sub(r\"\\'d\", \" would \", text)\n    text = re.sub(r\"\\'ll\", \" will \", text)\n    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n    text = re.sub('\\W', ' ', text)\n    text = re.sub('\\s+', ' ', text)\n    text = text.strip(' ')\n    \n    return text","metadata":{"execution":{"iopub.status.busy":"2023-05-08T23:37:28.453493Z","iopub.execute_input":"2023-05-08T23:37:28.455958Z","iopub.status.idle":"2023-05-08T23:37:28.465387Z","shell.execute_reply.started":"2023-05-08T23:37:28.455917Z","shell.execute_reply":"2023-05-08T23:37:28.464405Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def  textpreprocess(text):\n    \n    text = map(lambda x: x.lower(), text) \n    text = map(lambda x: re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", x), text) \n    text = map(lambda x: re.sub(re.compile(r\"<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});\"),\"\", x), text) \n    text = map(lambda x: re.sub(r'[^\\x00-\\x7f]',r' ', x), text) \n\n    emoji_pattern = re.compile(\n            '['\n            u'\\U0001F600-\\U0001F64F'  \n            u'\\U0001F300-\\U0001F5FF'  \n            u'\\U0001F680-\\U0001F6FF'  \n            u'\\U0001F1E0-\\U0001F1FF'  \n            u'\\U00002702-\\U000027B0'\n            u'\\U000024C2-\\U0001F251'\n            ']+',\n            flags=re.UNICODE)\n\n    text = map(lambda x: emoji_pattern.sub(r'', x), text) \n    text = map(lambda x: x.translate(str.maketrans('', '', string.punctuation)), text) # Remove punctuations\n    \n    \n    remove_digits = str.maketrans('', '', digits)\n    text = [i.translate(remove_digits) for i in text]\n    text = [w for w in text if not w in stop_words]\n    text = ' '.join([lemmatizer.lemmatize(w) for w in text])\n    text = text.strip()\n    return text","metadata":{"execution":{"iopub.status.busy":"2023-05-08T23:37:28.470209Z","iopub.execute_input":"2023-05-08T23:37:28.472691Z","iopub.status.idle":"2023-05-08T23:37:28.483557Z","shell.execute_reply.started":"2023-05-08T23:37:28.472642Z","shell.execute_reply":"2023-05-08T23:37:28.482625Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"execution":{"iopub.status.busy":"2023-05-08T23:37:28.488099Z","iopub.execute_input":"2023-05-08T23:37:28.490595Z","iopub.status.idle":"2023-05-08T23:37:30.014530Z","shell.execute_reply.started":"2023-05-08T23:37:28.490555Z","shell.execute_reply":"2023-05-08T23:37:30.013209Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Archive:  /usr/share/nltk_data/corpora/wordnet.zip\n   creating: /usr/share/nltk_data/corpora/wordnet/\n  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \n  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \n  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/README  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \n","output_type":"stream"}]},{"cell_type":"code","source":"X = X.apply(lambda x: stringprocess(x))\nword_tokens = X.apply(lambda x: word_tokenize(x))\n\npreprocess_text = word_tokens.apply(lambda x: textpreprocess(x))\npreprocess_text[0]","metadata":{"execution":{"iopub.status.busy":"2023-05-08T23:37:30.022141Z","iopub.execute_input":"2023-05-08T23:37:30.024457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_portion = 0.8\ntrain_size = int(len(preprocess_text) * training_portion)\n\ntrain_data = preprocess_text[0: train_size]\ntrain_labels = np.array(y[0: train_size])\n\nvalidation_data = preprocess_text[train_size:]\nvalidation_labels = np.array(y[train_size:])\n\n\nprint(len(train_data))\nprint(len(train_labels))\nprint(len(validation_data))\nprint(len(validation_labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_size = 500\noov_tok = '<OOV>'\n\ntokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\ntokenizer.fit_on_texts(train_data)\nword_index = tokenizer.word_index\ndict(list(word_index.items())[0:10])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_sequences = tokenizer.texts_to_sequences(train_data)\nprint(train_sequences[10])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_dim = 50\nmax_length = 70\ntrunc_type = 'post'  \npadding_type = 'post'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\nprint(len(train_sequences[0]))\nprint(len(train_padded[0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_padded[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_sequences = tokenizer.texts_to_sequences(validation_data)\nvalidation_padded = pad_sequences(validation_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n\nprint(len(validation_sequences))\nprint(validation_padded.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n\ndef decode_data(text):\n    return ' '.join([reverse_word_index.get(i, '?') for i in text])\nprint(decode_data(train_padded[10]))\nprint('---')\nprint(train_data[10])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n    tf.keras.layers.LSTM(64,activation='relu'),\n    tf.keras.layers.Dense(32, activation='relu'),\n    tf.keras.layers.Dense(16, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nnum_epochs = 5\nhistory = model.fit(train_padded, train_labels, epochs=num_epochs, validation_data=(validation_padded, validation_labels), verbose=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_graphs(history, string):\n    plt.plot(history.history[string])\n    plt.plot(history.history['val_'+string])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(string)\n    plt.legend([string, 'val_'+string])\n    plt.show()\n\nplot_graphs(history, \"accuracy\")\nplot_graphs(history, \"loss\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nseed_text = \"wonderful little production br br filming technique unassuming old time bbc fashion give comforting sometimes discomforting sense realism entire piece br br actor extremely well chosen michael sheen got polari voice pat truly see seamless editing guided reference williams diary entry well worth watching terrificly written performed piece masterful production one great master comedy life br br realism really come home little thing fantasy guard rather use traditional would ream technique remains solid disappears play knowledge sens particularly scene concerning orton halliwell set particularly flat halliwell mural decorating every surface terribly well done\"\ntoken_list = tokenizer.texts_to_sequences([seed_text])[0]\ntoken_list = pad_sequences([token_list], maxlen=max_length-1, padding=padding_type, truncating=trunc_type)\npredicted = (model.predict(token_list, verbose=0) > 0.5).astype(\"int32\")\n\nif predicted[0][0] == 0:\n    print(\"Negative\")\nelse:\n    print(\"Positive\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocess_text[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}